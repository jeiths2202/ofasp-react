// ì‹¤ì œ TensorFlow.js ê¸°ë°˜ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-cpu';
import '@tensorflow/tfjs-backend-webgl';
import * as use from '@tensorflow-models/universal-sentence-encoder';
import { DocumentChunk } from './ragService';

// ì‹¤ì œ ë²¡í„° ì„ë² ë”© ì¸í„°í˜ì´ìŠ¤
export interface RealVectorEmbedding {
  id: string;
  vector: Float32Array;
  metadata: {
    documentId: string;
    chunkIndex: number;
    text: string;
    language: 'ko' | 'ja';
    source: string;
    section?: string;
    timestamp: Date;
  };
}

// ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ì¸í„°í˜ì´ìŠ¤
export interface RealVectorSearchResult {
  embedding: RealVectorEmbedding;
  similarity: number;
  distance: number;
  chunk: DocumentChunk;
  score: number;
}

// ì‹¤ì œ TensorFlow.js ê¸°ë°˜ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
export class RealVectorDatabase {
  private model: use.UniversalSentenceEncoder | null = null;
  private embeddings: Map<string, RealVectorEmbedding> = new Map();
  private indexByLanguage: Map<string, RealVectorEmbedding[]> = new Map();
  private isInitialized = false;
  private isModelLoaded = false;
  private isDataLoaded = false;
  private lastLoadTime: Date | null = null;

  // ëª¨ë¸ ì´ˆê¸°í™” (ìºì‹± ì§€ì›)
  async initialize(): Promise<void> {
    // ì´ë¯¸ ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
    if (this.isModelLoaded && this.model) {
      console.log('ğŸ“¦ TensorFlow.js ëª¨ë¸ì´ ì´ë¯¸ ìºì‹œë¨ - ì¬ì‚¬ìš©');
      this.isInitialized = true;
      return;
    }

    console.log('ğŸ¤– TensorFlow.js ë°±ì—”ë“œ ì´ˆê¸°í™” ì¤‘...');
    
    try {
      // TensorFlow.js ë°±ì—”ë“œ ì¤€ë¹„ í™•ì¸
      await tf.ready();
      console.log('âœ… TensorFlow.js ë°±ì—”ë“œ ì¤€ë¹„ë¨:', tf.getBackend());
      
      console.log('ğŸ¤– TensorFlow.js Universal Sentence Encoder ëª¨ë¸ ë¡œë”© ì¤‘...');
      const startTime = Date.now();

      // ì‹¤ì œ Universal Sentence Encoder ëª¨ë¸ ë¡œë“œ
      this.model = await use.load();
      
      const loadTime = Date.now() - startTime;
      console.log(`âœ… ì‹¤ì œ ë²¡í„° ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (${loadTime}ms)`);
      console.log(`ğŸ“ ëª¨ë¸ ì°¨ì›: 512 (Universal Sentence Encoder)`);
      console.log(`ğŸ–¥ï¸ ì‚¬ìš© ì¤‘ì¸ ë°±ì—”ë“œ: ${tf.getBackend()}`);
      
      this.isModelLoaded = true;
      this.isInitialized = true;
    } catch (error) {
      console.error('âŒ TensorFlow.js ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error);
      console.error('ğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—”ë“œ:', tf.engine().backendNames);
      throw new Error('ì‹¤ì œ ë²¡í„° ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
    }
  }

  // ì‹¤ì œ ë¬¸ì„œ ì¶”ê°€ ë° ë²¡í„°í™” (ì¤‘ë³µ ë°©ì§€)
  async addDocument(document: DocumentChunk): Promise<void> {
    if (!this.model) {
      throw new Error('ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }

    // ì´ë¯¸ ì²˜ë¦¬ëœ ë¬¸ì„œì¸ì§€ í™•ì¸
    const docKey = `${document.id}_${document.metadata.source}`;
    const existingDoc = Array.from(this.embeddings.values()).find(
      emb => emb.metadata.documentId === document.id && emb.metadata.source === document.metadata.source
    );
    
    if (existingDoc) {
      console.log(`ğŸ“¦ ë¬¸ì„œê°€ ì´ë¯¸ ë²¡í„° DBì— ìºì‹œë¨: ${document.metadata.source}`);
      return;
    }

    console.log(`ğŸ”„ ì‹¤ì œ ë²¡í„° ì„ë² ë”© ìƒì„±: ${document.metadata.source}`);
    const startTime = Date.now();

    try {
      // ë¬¸ì„œë¥¼ ì‹¤ì œ ì²­í¬ë¡œ ë¶„í• 
      const chunks = this.chunkDocument(document);
      console.log(`ğŸ“„ ë¬¸ì„œë¥¼ ${chunks.length}ê°œ ì²­í¬ë¡œ ë¶„í• `);

      for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        const embeddingId = `${document.id}_chunk_${i}`;

        console.log(`ğŸ§® ì²­í¬ ${i + 1}/${chunks.length} ë²¡í„° ì„ë² ë”© ìƒì„± ì¤‘...`);
        
        // ì‹¤ì œ Universal Sentence Encoderë¡œ ì„ë² ë”© ìƒì„±
        const embeddings = await this.model.embed([chunk]);
        const embeddingArray = await embeddings.data();
        embeddings.dispose(); // ë©”ëª¨ë¦¬ í•´ì œ

        // Float32Arrayë¡œ ë³€í™˜
        const vector = new Float32Array(embeddingArray);

        const embedding: RealVectorEmbedding = {
          id: embeddingId,
          vector: vector,
          metadata: {
            documentId: document.id,
            chunkIndex: i,
            text: chunk,
            language: document.metadata.language,
            source: document.metadata.source,
            section: document.metadata.section,
            timestamp: new Date()
          }
        };

        this.embeddings.set(embeddingId, embedding);

        // ì–¸ì–´ë³„ ì¸ë±ìŠ¤ êµ¬ì¶•
        const langKey = document.metadata.language;
        if (!this.indexByLanguage.has(langKey)) {
          this.indexByLanguage.set(langKey, []);
        }
        this.indexByLanguage.get(langKey)!.push(embedding);

        console.log(`âœ… ì²­í¬ ${i + 1} ë²¡í„° ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: ${vector.length})`);
      }

      const processingTime = Date.now() - startTime;
      console.log(`ğŸ¯ ë¬¸ì„œ ë²¡í„°í™” ì™„ë£Œ: ${document.metadata.source} (${processingTime}ms)`);
      
      // ë°ì´í„° ë¡œë“œ ìƒíƒœ ì—…ë°ì´íŠ¸
      this.isDataLoaded = true;
      this.lastLoadTime = new Date();

    } catch (error) {
      console.error(`âŒ ë¬¸ì„œ ë²¡í„°í™” ì‹¤íŒ¨: ${document.metadata.source}`, error);
      throw error;
    }
  }

  // ì‹¤ì œ ìœ ì‚¬ë„ ê²€ìƒ‰
  async search(query: string, language: 'ko' | 'ja', limit: number = 10): Promise<RealVectorSearchResult[]> {
    if (!this.model) {
      throw new Error('ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }

    console.log(`ğŸ” ì‹¤ì œ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰: "${query}" (${language})`);
    const startTime = Date.now();

    try {
      // ì¿¼ë¦¬ë¥¼ ì‹¤ì œ ë²¡í„°ë¡œ ë³€í™˜
      const queryEmbeddings = await this.model.embed([query]);
      const queryVector = new Float32Array(await queryEmbeddings.data());
      queryEmbeddings.dispose();

      const results: RealVectorSearchResult[] = [];

      // ëª¨ë“  ì„ë² ë”©ê³¼ ì‹¤ì œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
      this.embeddings.forEach((embedding) => {
        const similarity = this.calculateCosineSimilarity(queryVector, embedding.vector);
        
        if (similarity > 0.1) { // ìµœì†Œ ì„ê³„ê°’
          results.push({
            embedding,
            similarity,
            distance: 1 - similarity,
            chunk: {
              id: embedding.metadata.documentId,
              content: embedding.metadata.text,
              metadata: {
                source: embedding.metadata.source,
                language: embedding.metadata.language,
                section: embedding.metadata.section
              }
            },
            score: similarity
          });
        }
      });

      // ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬
      results.sort((a, b) => b.similarity - a.similarity);

      const searchTime = Date.now() - startTime;
      console.log(`ğŸ¯ ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: ${results.length}ê°œ ê²°ê³¼ (${searchTime}ms)`);

      return results.slice(0, limit);

    } catch (error) {
      console.error('âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  // ì‹¤ì œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
  private calculateCosineSimilarity(vector1: Float32Array, vector2: Float32Array): number {
    if (vector1.length !== vector2.length) {
      throw new Error('ë²¡í„° ì°¨ì›ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤');
    }

    let dotProduct = 0;
    let magnitude1 = 0;
    let magnitude2 = 0;

    for (let i = 0; i < vector1.length; i++) {
      dotProduct += vector1[i] * vector2[i];
      magnitude1 += vector1[i] * vector1[i];
      magnitude2 += vector2[i] * vector2[i];
    }

    magnitude1 = Math.sqrt(magnitude1);
    magnitude2 = Math.sqrt(magnitude2);

    if (magnitude1 === 0 || magnitude2 === 0) {
      return 0;
    }

    return dotProduct / (magnitude1 * magnitude2);
  }

  // ë¬¸ì„œ ì²­í‚¹ (ì‹¤ì œ ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• )
  private chunkDocument(document: DocumentChunk): string[] {
    const content = document.content;
    const chunks: string[] = [];
    
    // ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    const sentences = content.split(/[.!?ã€‚ï¼ï¼Ÿ]/);
    
    let currentChunk = '';
    const maxChunkLength = 500; // í† í° ìˆ˜ ì œí•œ
    
    for (const sentence of sentences) {
      const trimmedSentence = sentence.trim();
      if (trimmedSentence.length === 0) continue;
      
      if (currentChunk.length + trimmedSentence.length > maxChunkLength) {
        if (currentChunk.length > 0) {
          chunks.push(currentChunk.trim());
          currentChunk = trimmedSentence;
        } else {
          chunks.push(trimmedSentence);
        }
      } else {
        currentChunk += (currentChunk.length > 0 ? '. ' : '') + trimmedSentence;
      }
    }
    
    if (currentChunk.length > 0) {
      chunks.push(currentChunk.trim());
    }
    
    return chunks.length > 0 ? chunks : [content];
  }

  // ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
  clear(): void {
    console.log('ğŸ—‘ï¸ ì‹¤ì œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”');
    this.embeddings.clear();
    this.indexByLanguage.clear();
  }

  // í†µê³„ ì •ë³´
  getStats(): { totalEmbeddings: number; byLanguage: Record<string, number> } {
    const stats = {
      totalEmbeddings: this.embeddings.size,
      byLanguage: {} as Record<string, number>
    };

    this.indexByLanguage.forEach((embeddings, language) => {
      stats.byLanguage[language] = embeddings.length;
    });

    return stats;
  }

  // ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
  isReady(): boolean {
    return this.isInitialized && this.model !== null;
  }
  
  // ë°ì´í„° ë¡œë“œ ìƒíƒœ í™•ì¸
  hasData(): boolean {
    return this.isDataLoaded && this.embeddings.size > 0;
  }
  
  // ìºì‹œ ìƒíƒœ ì •ë³´
  getCacheStatus(): {
    modelCached: boolean;
    dataCached: boolean;
    lastLoadTime: Date | null;
    totalDocuments: number;
  } {
    return {
      modelCached: this.isModelLoaded,
      dataCached: this.isDataLoaded,
      lastLoadTime: this.lastLoadTime,
      totalDocuments: this.embeddings.size
    };
  }

  // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´
  getMemoryUsage(): { embeddingCount: number; estimatedMB: number } {
    const embeddingCount = this.embeddings.size;
    // ê° ì„ë² ë”©ì€ ëŒ€ëµ 512 float32 = 2KB + ë©”íƒ€ë°ì´í„°
    const estimatedMB = (embeddingCount * 3) / 1024; // ëŒ€ëµ 3KB per embedding
    
    return { embeddingCount, estimatedMB };
  }

  // ë””ë²„ê·¸: ëª¨ë“  ì €ì¥ëœ ì„ë² ë”© ì •ë³´ ì¶œë ¥
  debugPrintAllEmbeddings(): void {
    console.log('=== ì‹¤ì œ ë²¡í„° DB ë””ë²„ê·¸ ì •ë³´ ===');
    console.log(`ì´ ì„ë² ë”© ìˆ˜: ${this.embeddings.size}`);
    
    this.indexByLanguage.forEach((embeddings, language) => {
      console.log(`${language}: ${embeddings.length}ê°œ ì„ë² ë”©`);
      
      if (embeddings.length > 0) {
        console.log(`  - ì²« ë²ˆì§¸ ì„ë² ë”© ì°¨ì›: ${embeddings[0].vector.length}`);
        console.log(`  - ë²¡í„° íƒ€ì…: ${embeddings[0].vector.constructor.name}`);
      }
    });

    if (this.embeddings.size > 0) {
      const firstEmbedding = Array.from(this.embeddings.values())[0];
      console.log('\n=== ìƒ˜í”Œ ì„ë² ë”© ì •ë³´ ===');
      console.log(`ì†ŒìŠ¤: ${firstEmbedding.metadata.source}`);
      console.log(`í…ìŠ¤íŠ¸: ${firstEmbedding.metadata.text.substring(0, 100)}...`);
      console.log(`ë²¡í„° ì°¨ì›: ${firstEmbedding.vector.length}`);
      console.log(`ë²¡í„° ìƒ˜í”Œ: [${Array.from(firstEmbedding.vector.slice(0, 5)).map(v => v.toFixed(4)).join(', ')}...]`);
    }
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const realVectorDatabase = new RealVectorDatabase();